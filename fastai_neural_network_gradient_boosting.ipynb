{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rubanzasilva/fastai-neural-network-gradient-boosting?scriptVersionId=188940590\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Binary Classification of Insurance Cross \n\nThe objective of this competition is to predict which customers respond positively to an automobile insurance offer.\n\nA company that has been offering health insurance to a segment of customers wants to find out whether their health insurance customers are willing to also get/sign up for their motor vehicle insurance plan ","metadata":{}},{"cell_type":"markdown","source":"## Library Imports","metadata":{}},{"cell_type":"code","source":"%pip install catboost\n%pip install optuna\n%pip install optuna_distributed\n%pip install openfe\n%pip install seaborn\n%pip install xgboost\n%pip install lightgbm\n%pip install fastkaggle\n%pip install h2o\n%pip install -Uqq fastbook\n%pip install -q -U autogluon.tabular\n%pip install autogluon\n#ip install --upgrade pip","metadata":{"_kg_hide-output":true,"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-19T08:13:23.066746Z","iopub.execute_input":"2024-07-19T08:13:23.067311Z","iopub.status.idle":"2024-07-19T08:19:20.188356Z","shell.execute_reply.started":"2024-07-19T08:13:23.067282Z","shell.execute_reply":"2024-07-19T08:19:20.187222Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.5)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.26.4)\nRequirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.2.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.11.4)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.1)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\nNote: you may need to restart the kernel to use updated packages.\nCollecting optuna_distributed\n  Downloading optuna_distributed-0.7.0-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: optuna>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from optuna_distributed) (3.6.1)\nRequirement already satisfied: dask[distributed] in /opt/conda/lib/python3.10/site-packages (from optuna_distributed) (2024.5.2)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from optuna_distributed) (13.7.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (2.0.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna>=3.1.0->optuna_distributed) (6.0.1)\nRequirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (8.1.7)\nRequirement already satisfied: cloudpickle>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (2.2.1)\nRequirement already satisfied: fsspec>=2021.09.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (2024.3.1)\nRequirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (1.4.2)\nRequirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (0.12.1)\nRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask[distributed]->optuna_distributed) (6.11.0)\nCollecting distributed==2024.5.2 (from dask[distributed]->optuna_distributed)\n  Downloading distributed-2024.5.2-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: jinja2>=2.10.3 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (3.1.2)\nRequirement already satisfied: locket>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (1.0.7)\nRequirement already satisfied: psutil>=5.7.2 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (5.9.3)\nRequirement already satisfied: sortedcontainers>=2.0.5 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (3.0.0)\nRequirement already satisfied: tornado>=6.0.4 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (6.3.3)\nRequirement already satisfied: urllib3>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (1.26.18)\nRequirement already satisfied: zict>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from distributed==2024.5.2->dask[distributed]->optuna_distributed) (3.0.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->optuna_distributed) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->optuna_distributed) (2.17.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna_distributed) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna_distributed) (4.9.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask[distributed]->optuna_distributed) (3.17.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->optuna_distributed) (0.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna>=3.1.0->optuna_distributed) (3.1.1)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1.0->optuna_distributed) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed==2024.5.2->dask[distributed]->optuna_distributed) (2.1.3)\nDownloading optuna_distributed-0.7.0-py3-none-any.whl (30 kB)\nDownloading distributed-2024.5.2-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: distributed, optuna_distributed\n  Attempting uninstall: distributed\n    Found existing installation: distributed 2024.1.1\n    Uninstalling distributed-2024.1.1:\n      Successfully uninstalled distributed-2024.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires distributed==2024.1.1, but you have distributed 2024.5.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed distributed-2024.5.2 optuna_distributed-0.7.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting openfe\n  Downloading openfe-0.0.12-py3-none-any.whl.metadata (667 bytes)\nRequirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.26.4)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from openfe) (2.2.1)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.2.2)\nRequirement already satisfied: lightgbm>=3.3.2 in /opt/conda/lib/python3.10/site-packages (from openfe) (4.2.0)\nRequirement already satisfied: scipy>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from openfe) (1.11.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openfe) (4.66.4)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openfe) (14.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->openfe) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->openfe) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->openfe) (1.16.0)\nDownloading openfe-0.0.12-py3-none-any.whl (21 kB)\nInstalling collected packages: openfe\nSuccessfully installed openfe-0.0.12\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.2.1)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.10/site-packages (from seaborn) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.11.4)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (4.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.11.4)\nNote: you may need to restart the kernel to use updated packages.\nCollecting fastkaggle\n  Downloading fastkaggle-0.0.8-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: fastcore>=1.4.5 in /opt/conda/lib/python3.10/site-packages (from fastkaggle) (1.5.43)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from fastkaggle) (1.6.14)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fastcore>=1.4.5->fastkaggle) (21.3)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (4.66.4)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->fastkaggle) (6.1.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->fastkaggle) (0.5.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fastcore>=1.4.5->fastkaggle) (3.1.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->fastkaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->fastkaggle) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle->fastkaggle) (3.6)\nDownloading fastkaggle-0.0.8-py3-none-any.whl (11 kB)\nInstalling collected packages: fastkaggle\nSuccessfully installed fastkaggle-0.0.8\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: h2o in /opt/conda/lib/python3.10/site-packages (3.46.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from h2o) (2.32.3)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from h2o) (0.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->h2o) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->h2o) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->h2o) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->h2o) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCollecting autogluon\n  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: autogluon.core==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (1.1.1)\nRequirement already satisfied: autogluon.features==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon) (1.1.1)\nRequirement already satisfied: autogluon.tabular==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.1.1)\nCollecting autogluon.multimodal==1.1.1 (from autogluon)\n  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\nCollecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: numpy<1.29,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\nRequirement already satisfied: scipy<1.13,>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.11.4)\nRequirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.1)\nRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.5)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.100)\nRequirement already satisfied: autogluon.common==1.1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.1.1)\nCollecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\nCollecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\nCollecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: jsonschema<4.22,>=4.18 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (4.20.0)\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: torchvision<0.19.0,>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.16.2)\nCollecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\nCollecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\nCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\nCollecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\nCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nCollecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.2)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.1)\nRequirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.3.10)\nCollecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pdf2image<1.19,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.17.0)\nRequirement already satisfied: xgboost<2.1,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.15)\nRequirement already satisfied: lightgbm<4.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.5)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\nRequirement already satisfied: pytorch-lightning<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.2.5)\nCollecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\nCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\nCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: orjson~=3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (3.9.10)\nCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (69.0.3)\nRequirement already satisfied: pydantic<3,>=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.5.3)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.9.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\nRequirement already satisfied: botocore<1.30.0,>=1.29.100 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.29.165)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.2)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2.19.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.3.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.23.2)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (23.3.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.43)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.3)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.16.2)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (0.11.2)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\nCollecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2023.12.25)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\nCollecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.12.1)\nCollecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.16.1)\nCollecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: protobuf>=3.20.1 in /opt/conda/lib/python3.10/site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.13.1)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.7)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.6.2.2)\nRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (14.0.2)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.1)\nCollecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.14)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.11.4)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.19.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.4.0)\nRequirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.59.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2.2)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.33.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2023.12.9)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.5.0)\nRequirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.2.0)\nRequirement already satisfied: statsmodels>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.3)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.6)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.3.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (23.5.26)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.14.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.9.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\nRequirement already satisfied: patsy>=0.5.4 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.3.8)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.11.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (4.1.0)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.11.1)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.20.0)\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.17.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.62.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.4)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\nCollecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\nCollecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading oss2-2.17.0.tar.gz (259 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting packaging>=20.0 (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nINFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\nCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\nINFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.0)\nDownloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\nDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\nDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\nDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\nDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\nDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=f27de4bae926adbe06d98743312bf92a7d549c8a1439c2ef242b91d939f38838\n  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=0982b462cfb191add39b58feb4d6e62dfee6e09e9bcf0fd40fd7fd5b88a9465d\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=9f445c829c6c3895dca11629dfbe790247295aeefe8611d22bc1964e042b6974\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\nInstalling collected packages: nvidia-ml-py3, antlr4-python3-runtime, triton, Pillow, openxlab, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, nltk, model-index, humanfriendly, window-ops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, utilsforecast, tokenizers, seqeval, scikit-image, opendatalab, onnxruntime, nvidia-cusolver-cu12, gluonts, gdown, aiohttp-cors, transformers, torch, statsforecast, ray, openmim, nlpaug, mlforecast, torchmetrics, pytorch-metric-learning, evaluate, accelerate, timm, optimum, lightning, autogluon.multimodal, autogluon.timeseries, autogluon\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.22.0\n    Uninstalling scikit-image-0.22.0:\n      Successfully uninstalled scikit-image-0.22.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: ray\n    Found existing installation: ray 2.9.0\n    Uninstalling ray-2.9.0:\n      Successfully uninstalled ray-2.9.0\n  Attempting uninstall: torchmetrics\n    Found existing installation: torchmetrics 1.4.0.post0\n    Uninstalling torchmetrics-1.4.0.post0:\n      Successfully uninstalled torchmetrics-1.4.0.post0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.3\n    Uninstalling timm-1.0.3:\n      Successfully uninstalled timm-1.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbumentations 1.4.0 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.3.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.multimodal-1.1.1 autogluon.timeseries-1.1.1 coloredlogs-15.0.1 evaluate-0.4.2 gdown-5.2.0 gluonts-0.15.1 humanfriendly-10.0 lightning-2.3.3 mlforecast-0.10.0 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnxruntime-1.18.1 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 pytorch-metric-learning-2.3.0 ray-2.10.0 scikit-image-0.20.0 seqeval-1.2.2 statsforecast-1.4.0 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 window-ops-0.0.15\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T08:19:20.190203Z","iopub.execute_input":"2024-07-19T08:19:20.190543Z","iopub.status.idle":"2024-07-19T08:19:20.81365Z","shell.execute_reply.started":"2024-07-19T08:19:20.190506Z","shell.execute_reply":"2024-07-19T08:19:20.812705Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e7/sample_submission.csv\n/kaggle/input/playground-series-s4e7/train.csv\n/kaggle/input/playground-series-s4e7/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"%pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:19:20.814843Z","iopub.execute_input":"2024-07-19T08:19:20.815298Z","iopub.status.idle":"2024-07-19T08:19:24.102116Z","shell.execute_reply.started":"2024-07-19T08:19:20.815273Z","shell.execute_reply":"2024-07-19T08:19:24.10099Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import fastbook\nfastbook.setup_book()\nfrom fastbook import *\nfrom fastai.tabular.all import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom numpy import random\nfrom tqdm import tqdm\nfrom ipywidgets import interact\n\nfrom fastai.imports import *\nnp.set_printoptions(linewidth=130)\n\n\nfrom pathlib import Path\nimport os\n\n\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score,accuracy_score,mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, cross_val_score\n\n\n\n#transformers and pipeline\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn import set_config\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom xgboost import XGBClassifier\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nfrom catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom optuna.visualization import plot_contour\nfrom optuna.visualization import plot_edf\nfrom optuna.visualization import plot_intermediate_values\nfrom optuna.visualization import plot_optimization_history\nfrom optuna.visualization import plot_parallel_coordinate\nfrom optuna.visualization import plot_param_importances\nfrom optuna.visualization import plot_slice\nfrom optuna.samplers import TPESampler\nimport warnings\n\n\nmatplotlib.rc('image', cmap='Greys')\n\nfrom fastkaggle import setup_comp\n\n\n\nfrom openfe import OpenFE, transform\nfrom autogluon.tabular import TabularDataset, TabularPredictor\n\n#from IPython.display import FileLink","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-19T08:19:24.105469Z","iopub.execute_input":"2024-07-19T08:19:24.105822Z","iopub.status.idle":"2024-07-19T08:19:35.006392Z","shell.execute_reply.started":"2024-07-19T08:19:24.105791Z","shell.execute_reply":"2024-07-19T08:19:35.005644Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:19:35.007434Z","iopub.execute_input":"2024-07-19T08:19:35.008128Z","iopub.status.idle":"2024-07-19T08:19:36.024332Z","shell.execute_reply.started":"2024-07-19T08:19:35.008102Z","shell.execute_reply":"2024-07-19T08:19:36.02343Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"playground-series-s4e7\n","output_type":"stream"}]},{"cell_type":"code","source":"path = Path('/kaggle/input/playground-series-s4e7/')\npath","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:19:36.025823Z","iopub.execute_input":"2024-07-19T08:19:36.026114Z","iopub.status.idle":"2024-07-19T08:19:36.033751Z","shell.execute_reply.started":"2024-07-19T08:19:36.026085Z","shell.execute_reply":"2024-07-19T08:19:36.032893Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Path('/kaggle/input/playground-series-s4e7')"},"metadata":{}}]},{"cell_type":"code","source":"train_df = pd.read_csv(path/'train.csv',index_col='id')\ntest_df = pd.read_csv(path/'test.csv',index_col='id')\nsub_df = pd.read_csv(path/'sample_submission.csv')\n#original_df = pd.read_csv('/kaggle/input/academic-success-dataset/data.csv',delimiter=';')","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:19:36.034907Z","iopub.execute_input":"2024-07-19T08:19:36.035228Z","iopub.status.idle":"2024-07-19T08:20:14.242698Z","shell.execute_reply.started":"2024-07-19T08:19:36.035199Z","shell.execute_reply":"2024-07-19T08:20:14.241868Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_df.shape,test_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:14.243908Z","iopub.execute_input":"2024-07-19T08:20:14.244183Z","iopub.status.idle":"2024-07-19T08:20:14.250078Z","shell.execute_reply.started":"2024-07-19T08:20:14.244159Z","shell.execute_reply":"2024-07-19T08:20:14.249174Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"((11504798, 11), (7669866, 10))"},"metadata":{}}]},{"cell_type":"markdown","source":"## Subset","metadata":{}},{"cell_type":"code","source":"train_subset = train_df.sample(n=1000000,replace=False)\ntest_subset = test_df.sample(n=500000,replace=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:13:15.871439Z","iopub.status.idle":"2024-07-19T08:13:15.871774Z","shell.execute_reply.started":"2024-07-19T08:13:15.871623Z","shell.execute_reply":"2024-07-19T08:13:15.871637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_subset.shape,test_subset.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-16T03:25:00.557222Z","iopub.execute_input":"2024-07-16T03:25:00.557546Z","iopub.status.idle":"2024-07-16T03:25:00.564053Z","shell.execute_reply.started":"2024-07-16T03:25:00.557519Z","shell.execute_reply":"2024-07-16T03:25:00.563082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cont_names,cat_names = cont_cat_split(train_subset, dep_var='Response')\n#splits = RandomSplitter(valid_pct=0.2)(range_of(train_subset))\n#to = TabularPandas(train_subset, procs=[Categorify, FillMissing,Normalize],\n#                  cat_names = cat_names,\n#                  cont_names = cont_names,\n#                  y_names='Response',\n#                  y_block=CategoryBlock(),\n#                  splits=splits)\n#dls = to.dataloaders(bs=64)\n#test_dl = dls.test_dl(test_subset)\n#X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n#X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Full Dataset\n\nBelow i use the fastai cont_cat_split which returns the values of a particular dataframe as either categorical or continous values depending on the cardinality of the column values which is how many levels a particular column has.\n\nThis function takes an argument of max_card whose default is 20. If the number of unique values is above the max_card, then that variables is considered to be continuos and vice versa.","metadata":{}},{"cell_type":"code","source":"cont_names,cat_names = cont_cat_split(train_df, dep_var='Response')\nlen(cat_names),len(cont_names)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:14.251419Z","iopub.execute_input":"2024-07-19T08:20:14.251774Z","iopub.status.idle":"2024-07-19T08:20:14.48521Z","shell.execute_reply.started":"2024-07-19T08:20:14.251745Z","shell.execute_reply":"2024-07-19T08:20:14.48427Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(5, 5)"},"metadata":{}}]},{"cell_type":"code","source":"cont_names","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:14.488273Z","iopub.execute_input":"2024-07-19T08:20:14.488625Z","iopub.status.idle":"2024-07-19T08:20:14.494338Z","shell.execute_reply.started":"2024-07-19T08:20:14.488601Z","shell.execute_reply":"2024-07-19T08:20:14.493368Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']"},"metadata":{}}]},{"cell_type":"code","source":"cat_names","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:14.495558Z","iopub.execute_input":"2024-07-19T08:20:14.495835Z","iopub.status.idle":"2024-07-19T08:20:14.503572Z","shell.execute_reply.started":"2024-07-19T08:20:14.495813Z","shell.execute_reply":"2024-07-19T08:20:14.502728Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['Gender',\n 'Driving_License',\n 'Previously_Insured',\n 'Vehicle_Age',\n 'Vehicle_Damage']"},"metadata":{}}]},{"cell_type":"markdown","source":"Below, i use fastai's RandomSplitter to divide my dataset into a train and validation set, in this example it creates a validation set with 20% of the training dataset.\n","metadata":{}},{"cell_type":"code","source":"splits = RandomSplitter(valid_pct=0.2)(range_of(train_df))","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:14.504802Z","iopub.execute_input":"2024-07-19T08:20:14.505132Z","iopub.status.idle":"2024-07-19T08:20:16.838137Z","shell.execute_reply.started":"2024-07-19T08:20:14.505096Z","shell.execute_reply":"2024-07-19T08:20:16.83728Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Below i build a TabularPandas Object which is a subclass of the Tabular class that has methods we can use to handle tabular data preparation and preprocessing.\n\nThis object takes in arguments where i define my training dataset and preprocessing steps i.e. Categorify, FillMissing,Normalize.\n\nWe also define our categorical and continuous variables resulting from the cont_cat_split.\nFurthermore, i define my Target variable, the y which in this case is Response, y_block represents the type of problem.\n\nLastly we have the splits argument which was defined above and represents the dataset split.","metadata":{}},{"cell_type":"code","source":"to = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='Response',\n                   y_block=CategoryBlock(),\n                   splits=splits)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:16.839588Z","iopub.execute_input":"2024-07-19T08:20:16.839888Z","iopub.status.idle":"2024-07-19T08:20:27.355225Z","shell.execute_reply.started":"2024-07-19T08:20:16.839864Z","shell.execute_reply":"2024-07-19T08:20:27.354416Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"to.xs.iloc[:2]","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:27.356733Z","iopub.execute_input":"2024-07-19T08:20:27.357076Z","iopub.status.idle":"2024-07-19T08:20:27.7613Z","shell.execute_reply.started":"2024-07-19T08:20:27.357044Z","shell.execute_reply":"2024-07-19T08:20:27.76035Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"         Gender  Driving_License  Previously_Insured  Vehicle_Age  \\\nid                                                                  \n3321034       2                2                   1            2   \n8422000       1                2                   1            2   \n\n         Vehicle_Damage       Age  Region_Code  Annual_Premium  \\\nid                                                               \n3321034               2 -0.825867    -1.417947        0.130413   \n8422000               2 -0.492411    -1.802805       -0.511315   \n\n         Policy_Sales_Channel   Vintage  \nid                                       \n3321034              0.732322 -0.786311  \n8422000              0.732322 -0.786311  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Driving_License</th>\n      <th>Previously_Insured</th>\n      <th>Vehicle_Age</th>\n      <th>Vehicle_Damage</th>\n      <th>Age</th>\n      <th>Region_Code</th>\n      <th>Annual_Premium</th>\n      <th>Policy_Sales_Channel</th>\n      <th>Vintage</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3321034</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-0.825867</td>\n      <td>-1.417947</td>\n      <td>0.130413</td>\n      <td>0.732322</td>\n      <td>-0.786311</td>\n    </tr>\n    <tr>\n      <th>8422000</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-0.492411</td>\n      <td>-1.802805</td>\n      <td>-0.511315</td>\n      <td>0.732322</td>\n      <td>-0.786311</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dls = to.dataloaders(bs=64)\ntest_dl = dls.test_dl(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:27.762576Z","iopub.execute_input":"2024-07-19T08:20:27.763329Z","iopub.status.idle":"2024-07-19T08:20:42.419546Z","shell.execute_reply.started":"2024-07-19T08:20:27.763295Z","shell.execute_reply":"2024-07-19T08:20:42.41868Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_test, y_test = to.valid.xs, to.valid.ys.values.ravel()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:42.420883Z","iopub.execute_input":"2024-07-19T08:20:42.421285Z","iopub.status.idle":"2024-07-19T08:20:44.736488Z","shell.execute_reply.started":"2024-07-19T08:20:42.421252Z","shell.execute_reply":"2024-07-19T08:20:44.735672Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"dls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2024-07-19T08:20:44.737629Z","iopub.execute_input":"2024-07-19T08:20:44.737935Z","iopub.status.idle":"2024-07-19T08:20:52.916952Z","shell.execute_reply.started":"2024-07-19T08:20:44.737909Z","shell.execute_reply":"2024-07-19T08:20:52.916003Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Driving_License</th>\n      <th>Previously_Insured</th>\n      <th>Vehicle_Age</th>\n      <th>Vehicle_Damage</th>\n      <th>Age</th>\n      <th>Region_Code</th>\n      <th>Annual_Premium</th>\n      <th>Policy_Sales_Channel</th>\n      <th>Vintage</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Female</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>24.000000</td>\n      <td>46.999999</td>\n      <td>25651.999781</td>\n      <td>151.999998</td>\n      <td>12.999999</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>&lt; 1 Year</td>\n      <td>Yes</td>\n      <td>29.000000</td>\n      <td>28.000000</td>\n      <td>55289.999728</td>\n      <td>26.000001</td>\n      <td>41.999996</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Female</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>22.000001</td>\n      <td>46.000000</td>\n      <td>25899.999969</td>\n      <td>159.999999</td>\n      <td>160.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Female</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1-2 Year</td>\n      <td>No</td>\n      <td>51.000000</td>\n      <td>28.000000</td>\n      <td>24793.000049</td>\n      <td>26.000001</td>\n      <td>177.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Male</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>27.000000</td>\n      <td>29.000000</td>\n      <td>2629.999079</td>\n      <td>151.999998</td>\n      <td>173.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>44.000000</td>\n      <td>32.000000</td>\n      <td>2629.999079</td>\n      <td>124.000000</td>\n      <td>298.000001</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Female</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>23.000001</td>\n      <td>8.000000</td>\n      <td>49181.000899</td>\n      <td>151.999998</td>\n      <td>179.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>44.000000</td>\n      <td>39.000000</td>\n      <td>2629.999079</td>\n      <td>26.000001</td>\n      <td>274.999998</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Female</td>\n      <td>1</td>\n      <td>1</td>\n      <td>&lt; 1 Year</td>\n      <td>No</td>\n      <td>25.000000</td>\n      <td>36.000000</td>\n      <td>2629.999079</td>\n      <td>151.000001</td>\n      <td>203.000001</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Male</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1-2 Year</td>\n      <td>Yes</td>\n      <td>55.000000</td>\n      <td>28.000000</td>\n      <td>32875.999897</td>\n      <td>26.000001</td>\n      <td>76.000001</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Neural Network","metadata":{}},{"cell_type":"code","source":"learn = tabular_learner(dls, metrics=RocAucBinary())","metadata":{"execution":{"iopub.status.busy":"2024-07-10T20:26:42.440762Z","iopub.execute_input":"2024-07-10T20:26:42.441136Z","iopub.status.idle":"2024-07-10T20:26:42.478183Z","shell.execute_reply.started":"2024-07-10T20:26:42.441106Z","shell.execute_reply":"2024-07-10T20:26:42.477127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.lr_find(suggest_funcs=(slide,valley))","metadata":{"execution":{"iopub.status.busy":"2024-07-10T00:52:17.676013Z","iopub.execute_input":"2024-07-10T00:52:17.676401Z","iopub.status.idle":"2024-07-10T00:52:20.00354Z","shell.execute_reply.started":"2024-07-10T00:52:17.676373Z","shell.execute_reply":"2024-07-10T00:52:20.002271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlearn.fit_one_cycle(8,0.005)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-10T00:52:38.238213Z","iopub.execute_input":"2024-07-10T00:52:38.238718Z","iopub.status.idle":"2024-07-10T01:11:51.555093Z","shell.execute_reply.started":"2024-07-10T00:52:38.238679Z","shell.execute_reply":"2024-07-10T01:11:51.553511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dl = test_dl\nnn_preds = learn.get_preds(dl=dl)\nnn_preds_x = learn.get_preds()[0]\na_preds, _ = learn.get_preds(dl=dl)\nnn_preds_y = a_preds.squeeze(1)\nnn_preds_proba = (a_preds[:, 1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit['Response'] = nn_preds_proba\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')\nsub","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network Ensemble","metadata":{}},{"cell_type":"code","source":"def ensemble():\n    learn = tabular_learner(dls, metrics=RocAucMulti())\n    with learn.no_bar(),learn.no_logging(): learn.fit(5, 0.005)\n    return learn.get_preds(test_dl=test_dl)[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:48:39.390138Z","iopub.execute_input":"2024-07-10T01:48:39.391363Z","iopub.status.idle":"2024-07-10T01:48:39.39824Z","shell.execute_reply.started":"2024-07-10T01:48:39.391321Z","shell.execute_reply":"2024-07-10T01:48:39.396914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learns = [ensemble() for _ in range(5)]","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds = torch.stack(learns).mean(0)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:51:11.367288Z","iopub.status.idle":"2024-07-10T01:51:11.368687Z","shell.execute_reply.started":"2024-07-10T01:51:11.368349Z","shell.execute_reply":"2024-07-10T01:51:11.368379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"%%time\nrf = RandomForestClassifier(100, min_samples_leaf=3)\nrf_model = rf.fit(X_train, y_train);\n\nrf_preds = tensor(rf_model.predict(test_dl.xs))\n\nrf_preds_x = tensor(rf_model.predict(X_test))\n\n#mse = mean_absolute_error(y_test, rf_preds_x)\n#rmse = np.sqrt(mse)\n\n#accuracy_score(y_test,rf_preds_x)\nroc_auc_score(y_test,rf_preds_x)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T03:35:32.720746Z","iopub.execute_input":"2024-07-10T03:35:32.721214Z","iopub.status.idle":"2024-07-10T04:54:19.414162Z","shell.execute_reply.started":"2024-07-10T03:35:32.721174Z","shell.execute_reply":"2024-07-10T04:54:19.410404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RandomForestClassifier??","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting","metadata":{}},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"xgb_optuna_params = {\n    'n_estimators': 929,\n    'alpha': 2.287466581490129e-05,\n    'subsample': 0.8766675651018592,\n    'colsample_bytree': 0.288332829334817,\n    'max_depth': 8,\n    'min_child_weight': 6,\n    'learning_rate': 0.024083411832750343,\n    'gamma': 0.001816649055813574\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-10T05:17:15.144216Z","iopub.execute_input":"2024-07-10T05:17:15.145372Z","iopub.status.idle":"2024-07-10T05:17:15.153342Z","shell.execute_reply.started":"2024-07-10T05:17:15.145322Z","shell.execute_reply":"2024-07-10T05:17:15.151816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(xgb.get_config())","metadata":{"execution":{"iopub.status.busy":"2024-07-17T04:32:56.79358Z","iopub.execute_input":"2024-07-17T04:32:56.794039Z","iopub.status.idle":"2024-07-17T04:32:56.807259Z","shell.execute_reply.started":"2024-07-17T04:32:56.794002Z","shell.execute_reply":"2024-07-17T04:32:56.806362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    'colsample_bylevel': 0.21416299403295808,\n    'colsample_bynode': 0.6208356380953189,\n    'colsample_bytree': 0.19219680400212635,\n    'gamma': 0.6051664515971382,\n    'max_bin': 682,\n    'max_delta_step': 5.264818337431145,\n    'max_depth': 68,\n    'min_child_weight': 5.23408291542125,\n    'n_estimators': 10000,\n    'n_jobs': -1,\n    'objective': \"binary:logistic\",\n    'reg_alpha': 0.46516016901463414,\n    'reg_lambda': 0.8410553418334902,\n    'subsample': 0.802533192662325,\n    'verbosity': 0,\n    'eval_metric': \"auc\",\n    #'early_stopping_rounds': 200,\n    'tree_method': 'gpu_hist'  # Use GPU acceleration\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-17T04:32:56.808789Z","iopub.execute_input":"2024-07-17T04:32:56.809104Z","iopub.status.idle":"2024-07-17T04:32:56.815293Z","shell.execute_reply.started":"2024-07-17T04:32:56.809074Z","shell.execute_reply":"2024-07-17T04:32:56.814298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nxgb_model = xgb.XGBClassifier(**xgb_params)\nxgb_model = xgb_model.fit(X_train, y_train)\n\nxgb_preds = tensor(xgb_model.predict(test_dl.xs))\nxgb_preds_proba = tensor(xgb_model.predict_proba(test_dl.xs))[:, 1]\n\nxgb_preds_x = tensor(xgb_model.predict(X_test))\nxgb_preds_x_proba = tensor(xgb_model.predict_proba(X_test))[:, 1]\n\nxgb_score = roc_auc_score(y_test,xgb_preds_x_proba)\nxgb_score","metadata":{"execution":{"iopub.status.busy":"2024-07-17T04:32:56.816516Z","iopub.execute_input":"2024-07-17T04:32:56.817054Z","iopub.status.idle":"2024-07-17T04:41:06.346819Z","shell.execute_reply.started":"2024-07-17T04:32:56.817022Z","shell.execute_reply":"2024-07-17T04:41:06.345766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-07-16T03:59:08.209538Z","iopub.execute_input":"2024-07-16T03:59:08.210364Z","iopub.status.idle":"2024-07-16T03:59:09.427922Z","shell.execute_reply.started":"2024-07-16T03:59:08.210331Z","shell.execute_reply":"2024-07-16T03:59:09.426539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit['Response'] = xgb_preds_proba\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')\nsub","metadata":{"execution":{"iopub.status.busy":"2024-07-16T03:59:13.01191Z","iopub.execute_input":"2024-07-16T03:59:13.012379Z","iopub.status.idle":"2024-07-16T03:59:37.45599Z","shell.execute_reply.started":"2024-07-16T03:59:13.012342Z","shell.execute_reply":"2024-07-16T03:59:37.454851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross validation implementation","metadata":{}},{"cell_type":"code","source":"#scores = cross_val_score(xgb_model,X_train, y_train,cv=5,scoring='roc_auc')\n#scores.mean()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T02:52:33.793579Z","iopub.execute_input":"2024-07-11T02:52:33.794Z","iopub.status.idle":"2024-07-11T02:59:59.154212Z","shell.execute_reply.started":"2024-07-11T02:52:33.793968Z","shell.execute_reply":"2024-07-11T02:59:59.152968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\n\nK_FOLDS = 5  # Number of folds for cross-validation\nkfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n\n# This part is just to demonstrate how the indices work\nfor train_index, test_index in kfold.split(train_df):\n    print(f'train: {len(train_index)} samples, test: {len(test_index)} samples')\n\nfold_scores = []\n\nfor train_index, val_index in kfold.split(X_train):\n    X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n    \n    # Train the model on the current fold\n    Xgb_model_fold = xgb.XGBClassifier(**xgb_params)\n    Xgb_model_fold.fit(X_fold_train, y_fold_train)\n    \n    # Predict probabilities on the validation set for the current fold\n    y_pred_fold = Xgb_model_fold.predict_proba(X_fold_val)[:, 1]\n    y_pred_fold_tt = Xgb_model_fold.predict_proba(test_dl.xs)[:, 1]\n    \n    # Calculate and store the AUC-ROC score for the current fold\n    score = roc_auc_score(y_fold_val, y_pred_fold)\n    fold_scores.append(score)\n\n# Calculate the average score across all folds\navg_score = np.mean(fold_scores)\nprint(f\"Average AUC-ROC Score Across All Folds: {avg_score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T04:45:32.862467Z","iopub.execute_input":"2024-07-17T04:45:32.862976Z","iopub.status.idle":"2024-07-17T05:17:14.764609Z","shell.execute_reply.started":"2024-07-17T04:45:32.862935Z","shell.execute_reply":"2024-07-17T05:17:14.76348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_fold_tt.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-17T05:22:33.139045Z","iopub.execute_input":"2024-07-17T05:22:33.139445Z","iopub.status.idle":"2024-07-17T05:22:33.146008Z","shell.execute_reply.started":"2024-07-17T05:22:33.139416Z","shell.execute_reply":"2024-07-17T05:22:33.145059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_score","metadata":{"execution":{"iopub.status.busy":"2024-07-17T05:23:10.393591Z","iopub.execute_input":"2024-07-17T05:23:10.393948Z","iopub.status.idle":"2024-07-17T05:23:10.399892Z","shell.execute_reply.started":"2024-07-17T05:23:10.393921Z","shell.execute_reply":"2024-07-17T05:23:10.398739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit['Response'] = y_pred_fold_tt\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')\nsub","metadata":{"execution":{"iopub.status.busy":"2024-07-17T05:23:34.309494Z","iopub.execute_input":"2024-07-17T05:23:34.31037Z","iopub.status.idle":"2024-07-17T05:23:55.429232Z","shell.execute_reply.started":"2024-07-17T05:23:34.31033Z","shell.execute_reply":"2024-07-17T05:23:55.42825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model = xgb.XGBClassifier(alpha=0.2271025051979102,\n                    gamma=0.07819541270693704,\n                    eta=0.294535700691525,\n                    max_depth=15,\n                    max_bin=174857,\n                    min_child_weight=1,\n                    max_child_weight=10,\n                    n_estimators=9500,\n                    subsample=0.8362024536878123,\n                    tree_method=\"hist\",\n                    device=\"cuda\",\n                    use_label_encoder=False,\n                    enable_categorical=True,\n                    eval_metric='auc',\n                    objective='binary:logistic',\n                    colsample_bytree=0.42784607351667425)\nxgb_model = xgb_model.fit(X_train, y_train)\n\nxgb_preds = tensor(xgb_model.predict(test_dl.xs))\n\nxgb_preds_x = tensor(xgb_model.predict(X_test))\n\n#accuracy_score(y_test,xgb_preds_x)\nxgb_score = roc_auc_score(y_test,xgb_preds_x)\nxgb_score","metadata":{"execution":{"iopub.status.busy":"2024-07-10T05:17:23.009192Z","iopub.execute_input":"2024-07-10T05:17:23.009682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"lgbm_params = {'n_estimators': 1190, 'learning_rate': 0.22952000374471332, 'max_depth': 13, 'reg_alpha': 8.200152384535924,\n          'reg_lambda': 4.285393733702208, \n          'num_leaves': 100, 'subsample': 0.6497981764924947, 'colsample_bytree': 0.37368304607248115,\\\n               'device_type':'gpu'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#ds subset\nlgbm_model = lgb.LGBMClassifier(**lgbm_params)\nlgbm_model = lgbm_model.fit(X_train, y_train)\n\n#test set preds\nlgbm_preds = tensor(lgbm_model.predict(test_dl.xs))\nlgbm_preds_prob = tensor(lgbm_model.predict_proba(test_dl.xs))\nlgbm_positive_preds = (lgbm_preds_prob[:, 1])\n\n#validation set preds\nlgbm_preds_x = tensor(lgbm_model.predict(X_test))\nlgbm_preds_x_prob = tensor(lgbm_model.predict_proba(X_test))\nlgbm_positive_preds_x = (lgbm_preds_x_prob[:, 1])\n\nlgbm_score = roc_auc_score(y_test,lgbm_positive_preds_x)\nlgbm_score\n\n#lgb_preds_x_prob = tensor(lgb_model.predict_proba(X_test))\n\nlgbm_score_prob = roc_auc_score(y_test,lgbm_positive_preds_x)\nlgbm_score_prob\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-19T10:20:15.043662Z","iopub.execute_input":"2024-07-19T10:20:15.044006Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1131646, number of negative: 8072193\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.201688 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 723\n[LightGBM] [Info] Number of data points in the train set: 9203839, number of used features: 10\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122954 -> initscore=-1.964752\n[LightGBM] [Info] Start training from score -1.964752\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"}]},{"cell_type":"code","source":"lgbm_score_prob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparamter optimization with Optuna","metadata":{}},{"cell_type":"code","source":"# finetuned optuna code\n%%time\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\n\ndef objective(trial):\n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n        'max_depth': trial.suggest_int('max_depth', 1, 15),\n        'device_type': 'gpu'\n    }\n    \n    K_FOLDS = 5  # Number of folds for cross-validation\n    kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n\n    fold_scores = []\n    \n    #for train_index, test_index in kfold.split(train_df):\n    #print(f'train: {len(train_index)} samples, test: {len(test_index)} samples')\n\n    for train_index, val_index in kfold.split(X_train):\n        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n        \n        # Train the model on the current fold\n        lgb_model_fold = lgb.LGBMClassifier(**params)  # Use params, not lgbm_params\n        lgb_model_fold.fit(X_fold_train, y_fold_train)\n        \n        # Predict probabilities on the validation set for the current fold\n        y_pred_fold = lgb_model_fold.predict_proba(X_fold_val)[:, 1]\n        \n        # Calculate and store the AUC-ROC score for the current fold\n        score = roc_auc_score(y_fold_val, y_pred_fold)\n        fold_scores.append(score)\n    \n    # Calculate the average score across all folds\n    return np.mean(fold_scores)\n\n# Create and run the study\nstudy = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\nstudy.optimize(objective, n_trials=100)\n\nprint('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best value:', study.best_value)\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T10:16:18.014435Z","iopub.execute_input":"2024-07-19T10:16:18.01529Z","iopub.status.idle":"2024-07-19T10:16:18.020714Z","shell.execute_reply.started":"2024-07-19T10:16:18.015257Z","shell.execute_reply":"2024-07-19T10:16:18.019753Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Best value: 0.880810142621536\nBest trial: {'num_leaves': 320, 'learning_rate': 0.13981961408994045, 'n_estimators': 843, 'subsample_for_bin': 172567, 'min_child_samples': 223, 'reg_alpha': 0.0028770084050677926, 'reg_lambda': 2.3761404778025532e-05, 'colsample_bytree': 0.9350638004692479, 'subsample': 0.9727470703757719, 'max_depth': 6}\n","output_type":"stream"}]},{"cell_type":"code","source":"lgb_optuna_run2_params  =  {\n    'num_leaves': 320, \n    'learning_rate': 0.13981961408994045, \n    'n_estimators': 843,\n    'subsample_for_bin': 172567, \n    'min_child_samples': 223,\n    'reg_alpha': 0.0028770084050677926,\n    'reg_lambda': 2.3761404778025532e-05,\n    'colsample_bytree': 0.9350638004692479,\n    'subsample': 0.9727470703757719,\n    'max_depth': 6,\n    'device_type':'gpu'\n}","metadata":{"execution":{"iopub.status.busy":"2024-07-19T10:19:09.16966Z","iopub.execute_input":"2024-07-19T10:19:09.170291Z","iopub.status.idle":"2024-07-19T10:19:09.175508Z","shell.execute_reply.started":"2024-07-19T10:19:09.170258Z","shell.execute_reply":"2024-07-19T10:19:09.174483Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### With Optuna tuned parameters","metadata":{}},{"cell_type":"code","source":"%%time\n#ds subset\nlgbm_model = lgb.LGBMClassifier(**lgbm_params)\nlgbm_model = lgbm_model.fit(X_train, y_train)\n\n#test set preds\nlgbm_preds = tensor(lgbm_model.predict(test_dl.xs))\nlgbm_preds_prob = tensor(lgbm_model.predict_proba(test_dl.xs))\nlgbm_positive_preds = (lgbm_preds_prob[:, 1])\n\n#validation set preds\nlgbm_preds_x = tensor(lgbm_model.predict(X_test))\nlgbm_preds_x_prob = tensor(lgbm_model.predict_proba(X_test))\nlgbm_positive_preds_x = (lgbm_preds_x_prob[:, 1])\n\nlgbm_score = roc_auc_score(y_test,lgbm_positive_preds_x)\nlgbm_score\n\n#lgb_preds_x_prob = tensor(lgb_model.predict_proba(X_test))\n\nlgbm_score_prob = roc_auc_score(y_test,lgbm_positive_preds_x)\nlgbm_score_prob\n","metadata":{"execution":{"iopub.status.busy":"2024-07-19T10:12:24.545356Z","iopub.status.idle":"2024-07-19T10:12:24.545828Z","shell.execute_reply.started":"2024-07-19T10:12:24.545599Z","shell.execute_reply":"2024-07-19T10:12:24.545618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost","metadata":{}},{"cell_type":"code","source":"cat_optuna_params = {\n    \n    'colsample_bylevel': 0.6383474716497279,\n    'learning_rate': 0.09475494290429642,\n    'random_strength': 0.07771221926568195,\n    'max_bin': 490,\n    'depth': 5,\n    'l2_leaf_reg': 5,\n    'boosting_type': 'Plain',\n    'bootstrap_type': 'Bernoulli',\n    'subsample': 0.8429457747642737,\n    'task_type': 'GPU'\n    \n}","metadata":{"execution":{"iopub.status.busy":"2024-07-19T09:45:23.234576Z","iopub.execute_input":"2024-07-19T09:45:23.234834Z","iopub.status.idle":"2024-07-19T09:45:23.245661Z","shell.execute_reply.started":"2024-07-19T09:45:23.234812Z","shell.execute_reply":"2024-07-19T09:45:23.244785Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%time\ncat_model = CatBoostClassifier(**cat_optuna_params)\ncat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n\n#test set preds\ncat_preds = tensor(cat_model.predict(test_dl.xs))\n\n\n#cat_preds_final = cat_preds.squeeze(1)\n\n#validation set preds\ncat_preds_x = tensor(cat_model.predict(X_test))\n\n#cat_preds_x_final = cat_preds_x.squeeze(1)\n\n#accuracy_score(y_test,cat_preds_x)\n\ncat_score = roc_auc_score(y_test,cat_preds_x)\ncat_score","metadata":{"execution":{"iopub.status.busy":"2024-07-19T09:45:23.246637Z","iopub.execute_input":"2024-07-19T09:45:23.246933Z","iopub.status.idle":"2024-07-19T09:45:25.496299Z","shell.execute_reply.started":"2024-07-19T09:45:23.24691Z","shell.execute_reply":"2024-07-19T09:45:25.495361Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)","File \u001b[0;32m<timed exec>:2\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:5220\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5218\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5220\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5221\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5222\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2385\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2385\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_train_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2395\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2396\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:2311\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2309\u001b[0m _check_param_types(params)\n\u001b[1;32m   2310\u001b[0m params \u001b[38;5;241m=\u001b[39m _params_type_cast(params)\n\u001b[0;32m-> 2311\u001b[0m \u001b[43m_check_train_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   2314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_set \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m_catboost.pyx:6393\u001b[0m, in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_catboost.pyx:6415\u001b[0m, in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n","\u001b[0;31mCatBoostError\u001b[0m: /src/catboost/catboost/private/libs/options/catboost_options.cpp:636: Error: rsm on GPU is supported for pairwise modes only"],"ename":"CatBoostError","evalue":"/src/catboost/catboost/private/libs/options/catboost_options.cpp:636: Error: rsm on GPU is supported for pairwise modes only","output_type":"error"}]},{"cell_type":"markdown","source":"# Model Predictions","metadata":{}},{"cell_type":"code","source":"model_preds = {\n    \"random forests\":roc_auc_score(y_test,rf_preds_x),\n    \"cat boost\":cat_score,\n    \"lgbm\":lgb_score,\n    \"xgboost\":roc_auc_score(y_test,xgb_preds_x),   \n}\n\n#model_preds_a = model_preds.sort()\nprint(model_preds)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T01:38:12.32286Z","iopub.execute_input":"2024-07-10T01:38:12.3234Z","iopub.status.idle":"2024-07-10T01:38:12.409442Z","shell.execute_reply.started":"2024-07-10T01:38:12.323366Z","shell.execute_reply":"2024-07-10T01:38:12.408294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_preds_x","metadata":{"execution":{"iopub.status.busy":"2024-07-19T09:45:25.497458Z","iopub.execute_input":"2024-07-19T09:45:25.497778Z","iopub.status.idle":"2024-07-19T09:45:25.536011Z","shell.execute_reply.started":"2024-07-19T09:45:25.497753Z","shell.execute_reply":"2024-07-19T09:45:25.534861Z"},"trusted":true},"execution_count":34,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcat_preds_x\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'cat_preds_x' is not defined"],"ename":"NameError","evalue":"name 'cat_preds_x' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Model Ensemble","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:42:42.149256Z","iopub.execute_input":"2024-07-10T15:42:42.149723Z","iopub.status.idle":"2024-07-10T15:42:43.276561Z","shell.execute_reply.started":"2024-07-10T15:42:42.149688Z","shell.execute_reply":"2024-07-10T15:42:43.274771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit.Response = xgb_preds\nsubmit.to_csv('submission.csv',index=False)\nsubmit","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:42:51.500609Z","iopub.execute_input":"2024-07-10T15:42:51.501069Z","iopub.status.idle":"2024-07-10T15:42:59.503456Z","shell.execute_reply.started":"2024-07-10T15:42:51.50103Z","shell.execute_reply":"2024-07-10T15:42:59.502194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-07-10T15:43:13.573822Z","iopub.execute_input":"2024-07-10T15:43:13.574268Z","iopub.status.idle":"2024-07-10T15:43:14.737677Z","shell.execute_reply.started":"2024-07-10T15:43:13.574232Z","shell.execute_reply":"2024-07-10T15:43:14.736194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(path/'sample_submission.csv')\nsubmit['Response'] = xgb_preds\nsubmit.to_csv('submission.csv', index=False)\nsub = pd.read_csv('submission.csv')\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}